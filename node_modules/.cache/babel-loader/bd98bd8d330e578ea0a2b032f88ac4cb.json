{"ast":null,"code":"/** */\n\n/*global BigInt */\n\n/*global BigInt64Array */\nimport { loadTokenizer } from './bert_tokenizer.ts';\nimport * as wasmFeatureDetect from 'wasm-feature-detect'; //Setup onnxruntime \n\nconst ort = require('onnxruntime-web'); //requires Cross-Origin-*-policy headers https://web.dev/coop-coep/\n\n/**\nconst simdResolver = wasmFeatureDetect.simd().then(simdSupported => {\n    console.log(\"simd is supported? \"+ simdSupported);\n    if (simdSupported) {\n      ort.env.wasm.numThreads = 3; \n      ort.env.wasm.simd = true;\n    } else {\n      ort.env.wasm.numThreads = 1; \n      ort.env.wasm.simd = false;\n    }\n});\n*/\n\n\nconst options = {\n  executionProviders: ['wasm'],\n  graphOptimizationLevel: 'all'\n};\nvar downLoadingModel = true; // const model = \"./xtremedistill-go-emotion-int8.onnx\";\n\nconst model = \"./classifier_dummy_in8.onnx\";\nconst session = ort.InferenceSession.create(model, options);\nsession.then(t => {\n  downLoadingModel = false; //warmup the VM\n\n  for (var i = 0; i < 10; i++) {\n    console.log(\"Inference warmup \" + i);\n    lm_inference(\"this is a warmup inference\");\n  }\n});\nconst tokenizer = loadTokenizer();\nconst EMOJI_DEFAULT_DISPLAY = [// [\"Emotion\", \"Score\"],\n// ['admiration 👏',0],\n// ['amusement 😂', 0],\n// ['neutral 😐',0],\n// ['approval 👍',0],\n// ['joy 😃',0],\n// ['gratitude 🙏',0],\n[\"Status\", \"Score\"], ['false 👍', 0], ['true 👎', 0] //   [0,0],\n//   [1,0],\n];\nconst EMOJIS = [// 'admiration 👏',\n// 'amusement 😂',\n// 'anger 😡',\n// 'annoyance 😒',\n// 'approval 👍',\n// 'caring 🤗',\n// 'confusion 😕',\n// 'curiosity 🤔',\n// 'desire 😍',\n// 'disappointment 😞',\n// 'disapproval 👎',\n// 'disgust 🤮',\n// 'embarrassment 😳',\n// 'excitement 🤩',\n// 'fear 😨',\n// 'gratitude 🙏',\n// 'grief 😢',\n// 'joy 😃',\n// 'love ❤️',\n// 'nervousness 😬',\n// 'optimism 🤞',\n// 'pride 😌',\n// 'realization 💡',\n// 'relief😅',\n// 'remorse 😞', \n// 'sadness 😞',\n// 'surprise 😲',\n// 'neutral 😐'\n'false 👍', 'true 👎' // 0,\n// 1\n];\n\nfunction isDownloading() {\n  return downLoadingModel;\n}\n\nfunction sortResult(a, b) {\n  if (a[1] === b[1]) {\n    return 0;\n  } else {\n    return a[1] < b[1] ? 1 : -1;\n  }\n}\n\nfunction sigmoid(t) {\n  return 1 / (1 + Math.pow(Math.E, -t));\n}\n\nfunction create_model_input(encoded) {\n  var input_ids = new Array(encoded.length + 2);\n  var attention_mask = new Array(encoded.length + 2);\n  var token_type_ids = new Array(encoded.length + 2);\n  input_ids[0] = BigInt(101);\n  attention_mask[0] = BigInt(1);\n  token_type_ids[0] = BigInt(0);\n  var i = 0;\n\n  for (; i < encoded.length; i++) {\n    input_ids[i + 1] = BigInt(encoded[i]);\n    attention_mask[i + 1] = BigInt(1);\n    token_type_ids[i + 1] = BigInt(0);\n  }\n\n  input_ids[i + 1] = BigInt(102);\n  attention_mask[i + 1] = BigInt(1);\n  token_type_ids[i + 1] = BigInt(0);\n  const sequence_length = input_ids.length;\n  input_ids = new ort.Tensor('int64', BigInt64Array.from(input_ids), [1, sequence_length]);\n  attention_mask = new ort.Tensor('int64', BigInt64Array.from(attention_mask), [1, sequence_length]);\n  token_type_ids = new ort.Tensor('int64', BigInt64Array.from(token_type_ids), [1, sequence_length]); // input_ids = new ort.Tensor('int32', BigInt32Array.from(input_ids), [1,sequence_length]);\n  // attention_mask = new ort.Tensor('int8', BigInt8Array.from(attention_mask), [1,sequence_length]);\n  // token_type_ids = new ort.Tensor('int8', BigInt8Array.from(token_type_ids), [1,sequence_length]);\n\n  return {\n    input_ids: input_ids,\n    attention_mask: attention_mask,\n    token_type_ids: token_type_ids\n  };\n}\n\nasync function lm_inference(text) {\n  try {\n    const encoded_ids = await tokenizer.then(t => {\n      return t.tokenize(text);\n    });\n\n    if (encoded_ids.length === 0) {\n      return [0.0, EMOJI_DEFAULT_DISPLAY];\n    }\n\n    const start = performance.now();\n    const model_input = create_model_input(encoded_ids);\n    const output = await session.then(s => {\n      return s.run(model_input, ['output_0']);\n    });\n    const duration = (performance.now() - start).toFixed(1);\n    const probs = output['output_0'].data.map(sigmoid).map(t => Math.floor(t * 100)); // const probs = output['output_0'][0].data.map(sigmoid).map( t => Math.floor(t*100));\n\n    const result = [];\n\n    for (var i = 0; i < EMOJIS.length; i++) {\n      const t = [EMOJIS[i], probs[i]];\n      result[i] = t;\n    }\n\n    result.sort(sortResult);\n    const result_list = [];\n    result_list[0] = [\"Status\", \"Score\"]; // for(i = 0; i < 6; i++) {\n\n    for (i = 0; i < 2; i++) {\n      result_list[i + 1] = result[i];\n    }\n\n    return [duration, result_list];\n  } catch (e) {\n    return [0.0, EMOJI_DEFAULT_DISPLAY];\n  }\n}\n\nexport let inference = lm_inference;\nexport let columnNames = EMOJI_DEFAULT_DISPLAY;\nexport let modelDownloadInProgress = isDownloading;","map":{"version":3,"names":["loadTokenizer","wasmFeatureDetect","ort","require","options","executionProviders","graphOptimizationLevel","downLoadingModel","model","session","InferenceSession","create","then","t","i","console","log","lm_inference","tokenizer","EMOJI_DEFAULT_DISPLAY","EMOJIS","isDownloading","sortResult","a","b","sigmoid","Math","pow","E","create_model_input","encoded","input_ids","Array","length","attention_mask","token_type_ids","BigInt","sequence_length","Tensor","BigInt64Array","from","text","encoded_ids","tokenize","start","performance","now","model_input","output","s","run","duration","toFixed","probs","data","map","floor","result","sort","result_list","e","inference","columnNames","modelDownloadInProgress"],"sources":["/Users/nguyentrungchinh/project_19/src/inference.js"],"sourcesContent":["/** */\n/*global BigInt */\n/*global BigInt64Array */\n\nimport { loadTokenizer } from './bert_tokenizer.ts';\nimport * as wasmFeatureDetect from 'wasm-feature-detect';\n\n//Setup onnxruntime \nconst ort = require('onnxruntime-web');\n\n//requires Cross-Origin-*-policy headers https://web.dev/coop-coep/\n/**\nconst simdResolver = wasmFeatureDetect.simd().then(simdSupported => {\n    console.log(\"simd is supported? \"+ simdSupported);\n    if (simdSupported) {\n      ort.env.wasm.numThreads = 3; \n      ort.env.wasm.simd = true;\n    } else {\n      ort.env.wasm.numThreads = 1; \n      ort.env.wasm.simd = false;\n    }\n});\n*/\n\nconst options = {\n  executionProviders: ['wasm'], \n  graphOptimizationLevel: 'all'\n};\n\nvar downLoadingModel = true;\n// const model = \"./xtremedistill-go-emotion-int8.onnx\";\nconst model = \"./classifier_dummy_in8.onnx\";\n\nconst session = ort.InferenceSession.create(model, options);\nsession.then(t => { \n  downLoadingModel = false;\n  //warmup the VM\n  for(var i = 0; i < 10; i++) {\n    console.log(\"Inference warmup \" + i);\n    lm_inference(\"this is a warmup inference\");\n  }\n});\n\nconst tokenizer = loadTokenizer()\n\nconst EMOJI_DEFAULT_DISPLAY = [\n  // [\"Emotion\", \"Score\"],\n  // ['admiration 👏',0],\n  // ['amusement 😂', 0],\n  // ['neutral 😐',0],\n  // ['approval 👍',0],\n  // ['joy 😃',0],\n  // ['gratitude 🙏',0],\n  [\"Status\", \"Score\"],\n  ['false 👍',0],\n  ['true 👎',0],\n//   [0,0],\n//   [1,0],\n];\n\nconst EMOJIS = [\n  // 'admiration 👏',\n  // 'amusement 😂',\n  // 'anger 😡',\n  // 'annoyance 😒',\n  // 'approval 👍',\n  // 'caring 🤗',\n  // 'confusion 😕',\n  // 'curiosity 🤔',\n  // 'desire 😍',\n  // 'disappointment 😞',\n  // 'disapproval 👎',\n  // 'disgust 🤮',\n  // 'embarrassment 😳',\n  // 'excitement 🤩',\n  // 'fear 😨',\n  // 'gratitude 🙏',\n  // 'grief 😢',\n  // 'joy 😃',\n  // 'love ❤️',\n  // 'nervousness 😬',\n  // 'optimism 🤞',\n  // 'pride 😌',\n  // 'realization 💡',\n  // 'relief😅',\n  // 'remorse 😞', \n  // 'sadness 😞',\n  // 'surprise 😲',\n  // 'neutral 😐'\n  'false 👍',\n  'true 👎'\n  // 0,\n  // 1\n];\n\nfunction isDownloading() {\n  return downLoadingModel;\n}\n\nfunction sortResult(a, b) {\n  if (a[1] === b[1]) {\n      return 0;\n  }\n  else {\n      return (a[1] < b[1]) ? 1 : -1;\n  }\n}\n\nfunction sigmoid(t) {\n  return 1/(1+Math.pow(Math.E, -t));\n}\n\nfunction create_model_input(encoded) {\n  var input_ids = new Array(encoded.length+2);\n  var attention_mask = new Array(encoded.length+2);\n  var token_type_ids = new Array(encoded.length+2);\n  input_ids[0] = BigInt(101);\n  attention_mask[0] = BigInt(1);\n  token_type_ids[0] = BigInt(0);\n  var i = 0;\n  for(; i < encoded.length; i++) { \n    input_ids[i+1] = BigInt(encoded[i]);\n    attention_mask[i+1] = BigInt(1);\n    token_type_ids[i+1] = BigInt(0);\n  }\n  input_ids[i+1] = BigInt(102);\n  attention_mask[i+1] = BigInt(1);\n  token_type_ids[i+1] = BigInt(0);\n  const sequence_length = input_ids.length;\n  input_ids = new ort.Tensor('int64', BigInt64Array.from(input_ids), [1,sequence_length]);\n  attention_mask = new ort.Tensor('int64', BigInt64Array.from(attention_mask), [1,sequence_length]);\n  token_type_ids = new ort.Tensor('int64', BigInt64Array.from(token_type_ids), [1,sequence_length]);\n\n  // input_ids = new ort.Tensor('int32', BigInt32Array.from(input_ids), [1,sequence_length]);\n  // attention_mask = new ort.Tensor('int8', BigInt8Array.from(attention_mask), [1,sequence_length]);\n  // token_type_ids = new ort.Tensor('int8', BigInt8Array.from(token_type_ids), [1,sequence_length]);\n\n  return {\n    input_ids: input_ids,\n    attention_mask: attention_mask,\n    token_type_ids:token_type_ids\n  }\n}\n\nasync function lm_inference(text) {\n  try { \n    const encoded_ids = await tokenizer.then(t => {\n      return t.tokenize(text); \n    });\n    if(encoded_ids.length === 0) {\n      return [0.0, EMOJI_DEFAULT_DISPLAY];\n    }\n    const start = performance.now();\n    const model_input = create_model_input(encoded_ids);\n    const output =  await session.then(s => { return s.run(model_input,['output_0'])});\n    const duration = (performance.now() - start).toFixed(1);\n    const probs = output['output_0'].data.map(sigmoid).map( t => Math.floor(t*100));\n    // const probs = output['output_0'][0].data.map(sigmoid).map( t => Math.floor(t*100));\n    \n    const result = [];\n    for(var i = 0; i < EMOJIS.length;i++) {\n      const t = [EMOJIS[i], probs[i]];\n      result[i] = t;\n    }\n    result.sort(sortResult); \n    \n    const result_list = [];\n    result_list[0] = [\"Status\", \"Score\"];\n    // for(i = 0; i < 6; i++) {\n    for(i = 0; i < 2; i++) {\n       result_list[i+1] = result[i];\n    }\n    return [duration,result_list];    \n  } catch (e) {\n    return [0.0,EMOJI_DEFAULT_DISPLAY];\n  }\n}    \n\nexport let inference = lm_inference \nexport let columnNames = EMOJI_DEFAULT_DISPLAY\nexport let modelDownloadInProgress = isDownloading\n"],"mappings":"AAAA;;AACA;;AACA;AAEA,SAASA,aAAT,QAA8B,qBAA9B;AACA,OAAO,KAAKC,iBAAZ,MAAmC,qBAAnC,C,CAEA;;AACA,MAAMC,GAAG,GAAGC,OAAO,CAAC,iBAAD,CAAnB,C,CAEA;;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAEA,MAAMC,OAAO,GAAG;EACdC,kBAAkB,EAAE,CAAC,MAAD,CADN;EAEdC,sBAAsB,EAAE;AAFV,CAAhB;AAKA,IAAIC,gBAAgB,GAAG,IAAvB,C,CACA;;AACA,MAAMC,KAAK,GAAG,6BAAd;AAEA,MAAMC,OAAO,GAAGP,GAAG,CAACQ,gBAAJ,CAAqBC,MAArB,CAA4BH,KAA5B,EAAmCJ,OAAnC,CAAhB;AACAK,OAAO,CAACG,IAAR,CAAaC,CAAC,IAAI;EAChBN,gBAAgB,GAAG,KAAnB,CADgB,CAEhB;;EACA,KAAI,IAAIO,CAAC,GAAG,CAAZ,EAAeA,CAAC,GAAG,EAAnB,EAAuBA,CAAC,EAAxB,EAA4B;IAC1BC,OAAO,CAACC,GAAR,CAAY,sBAAsBF,CAAlC;IACAG,YAAY,CAAC,4BAAD,CAAZ;EACD;AACF,CAPD;AASA,MAAMC,SAAS,GAAGlB,aAAa,EAA/B;AAEA,MAAMmB,qBAAqB,GAAG,CAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,QAAD,EAAW,OAAX,CAR4B,EAS5B,CAAC,UAAD,EAAY,CAAZ,CAT4B,EAU5B,CAAC,SAAD,EAAW,CAAX,CAV4B,CAW9B;AACA;AAZ8B,CAA9B;AAeA,MAAMC,MAAM,GAAG,CACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UA7Ba,EA8Bb,SA9Ba,CA+Bb;AACA;AAhCa,CAAf;;AAmCA,SAASC,aAAT,GAAyB;EACvB,OAAOd,gBAAP;AACD;;AAED,SAASe,UAAT,CAAoBC,CAApB,EAAuBC,CAAvB,EAA0B;EACxB,IAAID,CAAC,CAAC,CAAD,CAAD,KAASC,CAAC,CAAC,CAAD,CAAd,EAAmB;IACf,OAAO,CAAP;EACH,CAFD,MAGK;IACD,OAAQD,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAT,GAAgB,CAAhB,GAAoB,CAAC,CAA5B;EACH;AACF;;AAED,SAASC,OAAT,CAAiBZ,CAAjB,EAAoB;EAClB,OAAO,KAAG,IAAEa,IAAI,CAACC,GAAL,CAASD,IAAI,CAACE,CAAd,EAAiB,CAACf,CAAlB,CAAL,CAAP;AACD;;AAED,SAASgB,kBAAT,CAA4BC,OAA5B,EAAqC;EACnC,IAAIC,SAAS,GAAG,IAAIC,KAAJ,CAAUF,OAAO,CAACG,MAAR,GAAe,CAAzB,CAAhB;EACA,IAAIC,cAAc,GAAG,IAAIF,KAAJ,CAAUF,OAAO,CAACG,MAAR,GAAe,CAAzB,CAArB;EACA,IAAIE,cAAc,GAAG,IAAIH,KAAJ,CAAUF,OAAO,CAACG,MAAR,GAAe,CAAzB,CAArB;EACAF,SAAS,CAAC,CAAD,CAAT,GAAeK,MAAM,CAAC,GAAD,CAArB;EACAF,cAAc,CAAC,CAAD,CAAd,GAAoBE,MAAM,CAAC,CAAD,CAA1B;EACAD,cAAc,CAAC,CAAD,CAAd,GAAoBC,MAAM,CAAC,CAAD,CAA1B;EACA,IAAItB,CAAC,GAAG,CAAR;;EACA,OAAMA,CAAC,GAAGgB,OAAO,CAACG,MAAlB,EAA0BnB,CAAC,EAA3B,EAA+B;IAC7BiB,SAAS,CAACjB,CAAC,GAAC,CAAH,CAAT,GAAiBsB,MAAM,CAACN,OAAO,CAAChB,CAAD,CAAR,CAAvB;IACAoB,cAAc,CAACpB,CAAC,GAAC,CAAH,CAAd,GAAsBsB,MAAM,CAAC,CAAD,CAA5B;IACAD,cAAc,CAACrB,CAAC,GAAC,CAAH,CAAd,GAAsBsB,MAAM,CAAC,CAAD,CAA5B;EACD;;EACDL,SAAS,CAACjB,CAAC,GAAC,CAAH,CAAT,GAAiBsB,MAAM,CAAC,GAAD,CAAvB;EACAF,cAAc,CAACpB,CAAC,GAAC,CAAH,CAAd,GAAsBsB,MAAM,CAAC,CAAD,CAA5B;EACAD,cAAc,CAACrB,CAAC,GAAC,CAAH,CAAd,GAAsBsB,MAAM,CAAC,CAAD,CAA5B;EACA,MAAMC,eAAe,GAAGN,SAAS,CAACE,MAAlC;EACAF,SAAS,GAAG,IAAI7B,GAAG,CAACoC,MAAR,CAAe,OAAf,EAAwBC,aAAa,CAACC,IAAd,CAAmBT,SAAnB,CAAxB,EAAuD,CAAC,CAAD,EAAGM,eAAH,CAAvD,CAAZ;EACAH,cAAc,GAAG,IAAIhC,GAAG,CAACoC,MAAR,CAAe,OAAf,EAAwBC,aAAa,CAACC,IAAd,CAAmBN,cAAnB,CAAxB,EAA4D,CAAC,CAAD,EAAGG,eAAH,CAA5D,CAAjB;EACAF,cAAc,GAAG,IAAIjC,GAAG,CAACoC,MAAR,CAAe,OAAf,EAAwBC,aAAa,CAACC,IAAd,CAAmBL,cAAnB,CAAxB,EAA4D,CAAC,CAAD,EAAGE,eAAH,CAA5D,CAAjB,CAnBmC,CAqBnC;EACA;EACA;;EAEA,OAAO;IACLN,SAAS,EAAEA,SADN;IAELG,cAAc,EAAEA,cAFX;IAGLC,cAAc,EAACA;EAHV,CAAP;AAKD;;AAED,eAAelB,YAAf,CAA4BwB,IAA5B,EAAkC;EAChC,IAAI;IACF,MAAMC,WAAW,GAAG,MAAMxB,SAAS,CAACN,IAAV,CAAeC,CAAC,IAAI;MAC5C,OAAOA,CAAC,CAAC8B,QAAF,CAAWF,IAAX,CAAP;IACD,CAFyB,CAA1B;;IAGA,IAAGC,WAAW,CAACT,MAAZ,KAAuB,CAA1B,EAA6B;MAC3B,OAAO,CAAC,GAAD,EAAMd,qBAAN,CAAP;IACD;;IACD,MAAMyB,KAAK,GAAGC,WAAW,CAACC,GAAZ,EAAd;IACA,MAAMC,WAAW,GAAGlB,kBAAkB,CAACa,WAAD,CAAtC;IACA,MAAMM,MAAM,GAAI,MAAMvC,OAAO,CAACG,IAAR,CAAaqC,CAAC,IAAI;MAAE,OAAOA,CAAC,CAACC,GAAF,CAAMH,WAAN,EAAkB,CAAC,UAAD,CAAlB,CAAP;IAAuC,CAA3D,CAAtB;IACA,MAAMI,QAAQ,GAAG,CAACN,WAAW,CAACC,GAAZ,KAAoBF,KAArB,EAA4BQ,OAA5B,CAAoC,CAApC,CAAjB;IACA,MAAMC,KAAK,GAAGL,MAAM,CAAC,UAAD,CAAN,CAAmBM,IAAnB,CAAwBC,GAAxB,CAA4B9B,OAA5B,EAAqC8B,GAArC,CAA0C1C,CAAC,IAAIa,IAAI,CAAC8B,KAAL,CAAW3C,CAAC,GAAC,GAAb,CAA/C,CAAd,CAXE,CAYF;;IAEA,MAAM4C,MAAM,GAAG,EAAf;;IACA,KAAI,IAAI3C,CAAC,GAAG,CAAZ,EAAeA,CAAC,GAAGM,MAAM,CAACa,MAA1B,EAAiCnB,CAAC,EAAlC,EAAsC;MACpC,MAAMD,CAAC,GAAG,CAACO,MAAM,CAACN,CAAD,CAAP,EAAYuC,KAAK,CAACvC,CAAD,CAAjB,CAAV;MACA2C,MAAM,CAAC3C,CAAD,CAAN,GAAYD,CAAZ;IACD;;IACD4C,MAAM,CAACC,IAAP,CAAYpC,UAAZ;IAEA,MAAMqC,WAAW,GAAG,EAApB;IACAA,WAAW,CAAC,CAAD,CAAX,GAAiB,CAAC,QAAD,EAAW,OAAX,CAAjB,CAtBE,CAuBF;;IACA,KAAI7C,CAAC,GAAG,CAAR,EAAWA,CAAC,GAAG,CAAf,EAAkBA,CAAC,EAAnB,EAAuB;MACpB6C,WAAW,CAAC7C,CAAC,GAAC,CAAH,CAAX,GAAmB2C,MAAM,CAAC3C,CAAD,CAAzB;IACF;;IACD,OAAO,CAACqC,QAAD,EAAUQ,WAAV,CAAP;EACD,CA5BD,CA4BE,OAAOC,CAAP,EAAU;IACV,OAAO,CAAC,GAAD,EAAKzC,qBAAL,CAAP;EACD;AACF;;AAED,OAAO,IAAI0C,SAAS,GAAG5C,YAAhB;AACP,OAAO,IAAI6C,WAAW,GAAG3C,qBAAlB;AACP,OAAO,IAAI4C,uBAAuB,GAAG1C,aAA9B"},"metadata":{},"sourceType":"module"}