{"version":3,"sources":["webpack://onnxruntime-common/webpack/bootstrap","webpack://onnxruntime-common/webpack/runtime/define property getters","webpack://onnxruntime-common/webpack/runtime/hasOwnProperty shorthand","webpack://onnxruntime-common/webpack/runtime/make namespace object","webpack://onnxruntime-common/./lib/backend-impl.ts","webpack://onnxruntime-common/./lib/env.ts","webpack://onnxruntime-common/./lib/env-impl.ts","webpack://onnxruntime-common/./lib/tensor-impl.ts","webpack://onnxruntime-common/./lib/tensor.ts","webpack://onnxruntime-common/./lib/inference-session-impl.ts","webpack://onnxruntime-common/./lib/inference-session.ts"],"names":["__webpack_require__","exports","definition","key","o","Object","defineProperty","enumerable","get","obj","prop","prototype","hasOwnProperty","call","Symbol","toStringTag","value","backends","backendsSortedByPriority","registerBackend","name","backend","priority","init","createSessionHandler","TypeError","currentBackend","undefined","Error","i","length","splice","push","env","this","wasm","webgl","logLevelInternal","indexOf","isBigInt64ArrayAvailable","BigInt64Array","from","isBigUint64ArrayAvailable","BigUint64Array","NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP","Map","Float32Array","Uint8Array","Int8Array","Uint16Array","Int16Array","Int32Array","Float64Array","Uint32Array","NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP","set","Tensor","arg0","arg1","arg2","type","data","dims","Array","isArray","typedArrayConstructor","firstElementType","mappedType","constructor","size","dim","Number","isSafeInteger","RangeError","calculateSize","InferenceSession","handler","feeds","fetches","options","isFetchesEmpty","outputNames","isFetches","arg1Keys","getOwnPropertyNames","v","inputNames","results","run","returnValue","arg3","filePathOrUint8Array","ArrayBuffer","SharedArrayBuffer","buffer","byteOffset","byteLength","backendHints","executionProviders","map","async","backendNames","errors","backendName","backendInfo","initialized","aborted","isInitializing","initPromise","e","err","join","resolveBackend","startProfiling","endProfiling"],"mappings":";;;;;mBACA,IAAIA,EAAsB,CCA1B,EAAwB,CAACC,EAASC,KACjC,IAAI,IAAIC,KAAOD,EACXF,EAAoBI,EAAEF,EAAYC,KAASH,EAAoBI,EAAEH,EAASE,IAC5EE,OAAOC,eAAeL,EAASE,EAAK,CAAEI,YAAY,EAAMC,IAAKN,EAAWC,MCJ3E,EAAwB,CAACM,EAAKC,IAAUL,OAAOM,UAAUC,eAAeC,KAAKJ,EAAKC,GCClF,EAAyBT,IACH,oBAAXa,QAA0BA,OAAOC,aAC1CV,OAAOC,eAAeL,EAASa,OAAOC,YAAa,CAAEC,MAAO,WAE7DX,OAAOC,eAAeL,EAAS,aAAc,CAAEe,OAAO,M,yFCSvD,MAAMC,EAA0C,GAC1CC,EAAqC,GAY9BC,EAAkB,CAACC,EAAcC,EAAkBC,KAC9D,IAAID,GAAmC,mBAAjBA,EAAQE,MAA+D,mBAAjCF,EAAQG,qBAsBpE,MAAM,IAAIC,UAAU,uBAtBpB,CACE,MAAMC,EAAiBT,EAASG,GAChC,QAAuBO,IAAnBD,EAEG,IAAIA,EAAeL,UAAYA,EACpC,OAEA,MAAM,IAAIO,MAAM,YAAYR,4BAG9B,GAPEH,EAASG,GAAQ,CAACC,UAASC,YAOzBA,GAAY,EAAG,CACjB,IAAK,IAAIO,EAAI,EAAGA,EAAIX,EAAyBY,OAAQD,IACnD,GAAIZ,EAASC,EAAyBW,IAAIP,UAAYA,EAEpD,YADAJ,EAAyBa,OAAOF,EAAG,EAAGT,GAI1CF,EAAyBc,KAAKZ,MCwEvBa,EAAW,IC/GjB,MACL,cACEC,KAAKC,KAAO,GACZD,KAAKE,MAAQ,GACbF,KAAKG,iBAAmB,UAI1B,aAAarB,GACX,QAAcW,IAAVX,EAAJ,CAGA,GAAqB,iBAAVA,IAA2F,IAArE,CAAC,UAAW,OAAQ,UAAW,QAAS,SAASsB,QAAQtB,GACxF,MAAM,IAAIY,MAAM,8BAA8BZ,KAEhDkB,KAAKG,iBAAmBrB,GAE1B,eACE,OAAOkB,KAAKG,mBCXVE,EAAoD,oBAAlBC,eAA+D,mBAAvBA,cAAcC,KACxFC,EAAsD,oBAAnBC,gBAAiE,mBAAxBA,eAAeF,KAG3FG,EAAwC,IAAIC,IAA6C,CAC7F,CAAC,UAAWC,cACZ,CAAC,QAASC,YACV,CAAC,OAAQC,WACT,CAAC,SAAUC,aACX,CAAC,QAASC,YACV,CAAC,QAASC,YACV,CAAC,OAAQJ,YACT,CAAC,UAAWK,cACZ,CAAC,SAAUC,eAIPC,EAAwC,IAAIT,IAAiD,CACjG,CAACC,aAAc,WACf,CAACC,WAAY,SACb,CAACC,UAAW,QACZ,CAACC,YAAa,UACd,CAACC,WAAY,SACb,CAACC,WAAY,SACb,CAACC,aAAc,WACf,CAACC,YAAa,YAGZd,IACFK,EAAsCW,IAAI,QAASf,eACnDc,EAAsCC,IAAIf,cAAe,UAEvDE,IACFE,EAAsCW,IAAI,SAAUZ,gBACpDW,EAAsCC,IAAIZ,eAAgB,WAuBrD,MAAMa,EAIX,YACIC,EAAoDC,EACpDC,GACF,IAAIC,EACAC,EACAC,EAEJ,GAAoB,iBAATL,EAMT,GAFAG,EAAOH,EACPK,EAAOH,EACM,WAATF,EAAmB,CAErB,IAAKM,MAAMC,QAAQN,GACjB,MAAM,IAAIjC,UAAU,kDAItBoC,EAAOH,MACF,CAEL,MAAMO,EAAwBrB,EAAsCpC,IAAIiD,GACxE,QAA8B9B,IAA1BsC,EACF,MAAM,IAAIxC,UAAU,4BAA4BgC,MAElD,GAAIM,MAAMC,QAAQN,GAKhBG,EAAQI,EAA8BxB,KAAKiB,OACtC,MAAIA,aAAgBO,GAGzB,MAAM,IAAIxC,UAAU,KAAKmC,mCAAsCK,KAF/DJ,EAAOH,QAUX,GADAI,EAAOJ,EACHK,MAAMC,QAAQP,GAAO,CAEvB,GAAoB,IAAhBA,EAAK3B,OACP,MAAM,IAAIL,UAAU,uDAEtB,MAAMyC,SAA0BT,EAAK,GACrC,GAAyB,WAArBS,EACFN,EAAO,SACPC,EAAOJ,MACF,IAAyB,YAArBS,EAOT,MAAM,IAAIzC,UAAU,uCAAuCyC,MAN3DN,EAAO,OAIPC,EAAOd,WAAWN,KAAKgB,QAIpB,CAEL,MAAMU,EACFb,EAAsC9C,IAAIiD,EAAKW,aACnD,QAAmBzC,IAAfwC,EACF,MAAM,IAAI1C,UAAU,qCAAqCgC,EAAKW,gBAEhER,EAAOO,EACPN,EAAOJ,EAKX,QAAa9B,IAATmC,EAEFA,EAAO,CAACD,EAAK/B,aACR,IAAKiC,MAAMC,QAAQF,GACxB,MAAM,IAAIrC,UAAU,0CAItB,MAAM4C,EAtGY,CAACP,IACrB,IAAIO,EAAO,EACX,IAAK,IAAIxC,EAAI,EAAGA,EAAIiC,EAAKhC,OAAQD,IAAK,CACpC,MAAMyC,EAAMR,EAAKjC,GACjB,GAAmB,iBAARyC,IAAqBC,OAAOC,cAAcF,GACnD,MAAM,IAAI7C,UAAU,QAAQI,+BAA+ByC,KAE7D,GAAIA,EAAM,EACR,MAAM,IAAIG,WAAW,QAAQ5C,2CAA2CyC,KAE1ED,GAAQC,EAEV,OAAOD,GA0FQK,CAAcZ,GAC3B,GAAIO,IAASR,EAAK/B,OAChB,MAAM,IAAIF,MAAM,iBAAiByC,iCAAoCR,EAAK/B,YAG5EI,KAAK4B,KAAOA,EACZ5B,KAAK0B,KAAOA,EACZ1B,KAAK2B,KAAOA,EACZ3B,KAAKmC,KAAOA,EAYd,QAAQP,GACN,OAAO,IAAIN,EAAOtB,KAAK0B,KAAM1B,KAAK2B,KAAMC,IC2DrC,MAAM,EAASN,EC9Nf,MAAMmB,EACX,YAAoBC,GAClB1C,KAAK0C,QAAUA,EAIjB,UAAUC,EAAkBnB,EAA+BC,GACzD,MAAMmB,EAA4C,GAClD,IAAIC,EAAsB,GAE1B,GAAqB,iBAAVF,GAAgC,OAAVA,GAAkBA,aAAiB,GAAUd,MAAMC,QAAQa,GAC1F,MAAM,IAAIpD,UACN,iGAGN,IAAIuD,GAAiB,EAErB,GAAoB,iBAATtB,EAAmB,CAC5B,GAAa,OAATA,EACF,MAAM,IAAIjC,UAAU,2CAEtB,GAAIiC,aAAgB,EAClB,MAAM,IAAIjC,UAAU,gCAGtB,GAAIsC,MAAMC,QAAQN,GAAO,CACvB,GAAoB,IAAhBA,EAAK5B,OACP,MAAM,IAAIL,UAAU,uCAEtBuD,GAAiB,EAEjB,IAAK,MAAM5D,KAAQsC,EAAM,CACvB,GAAoB,iBAATtC,EACT,MAAM,IAAIK,UAAU,kDAEtB,IAAwC,IAApCS,KAAK+C,YAAY3C,QAAQlB,GAC3B,MAAM,IAAIqD,WAAW,2CAA2CrD,MAElE0D,EAAQ1D,GAAQ,KAGlB,GAAoB,iBAATuC,GAA8B,OAATA,EAC9BoB,EAAUpB,OACL,QAAoB,IAATA,EAChB,MAAM,IAAIlC,UAAU,oCAEjB,CAGL,IAAIyD,GAAY,EAChB,MAAMC,EAAW9E,OAAO+E,oBAAoB1B,GAC5C,IAAK,MAAMtC,KAAQc,KAAK+C,YACtB,IAAgC,IAA5BE,EAAS7C,QAAQlB,GAAc,CACjC,MAAMiE,EAAK3B,EAA4DtC,IAC7D,OAANiE,GAAcA,aAAa,KAC7BH,GAAY,EACZF,GAAiB,EACjBF,EAAQ1D,GAAQiE,GAKtB,GAAIH,GACF,GAAoB,iBAATvB,GAA8B,OAATA,EAC9BoB,EAAUpB,OACL,QAAoB,IAATA,EAChB,MAAM,IAAIlC,UAAU,qCAGtBsD,EAAUrB,QAGT,QAAoB,IAATA,EAChB,MAAM,IAAIjC,UAAU,2DAItB,IAAK,MAAML,KAAQc,KAAKoD,WACtB,QAA2B,IAAhBT,EAAMzD,GACf,MAAM,IAAIQ,MAAM,UAAUR,6BAK9B,GAAI4D,EACF,IAAK,MAAM5D,KAAQc,KAAK+C,YACtBH,EAAQ1D,GAAQ,KAMpB,MAAMmE,QAAgBrD,KAAK0C,QAAQY,IAAIX,EAAOC,EAASC,GACjDU,EAA2C,GACjD,IAAK,MAAMtF,KAAOoF,EACZlF,OAAOO,eAAeC,KAAK0E,EAASpF,KACtCsF,EAAYtF,GAAO,IAAI,EAAOoF,EAAQpF,GAAKyD,KAAM2B,EAAQpF,GAAK0D,KAAM0B,EAAQpF,GAAK2D,OAGrF,OAAO2B,EAQT,oBACIhC,EAAyCC,EAA8BC,EACvE+B,GAEF,IAAIC,EACAZ,EAA0B,GAE9B,GAAoB,iBAATtB,GAET,GADAkC,EAAuBlC,EACH,iBAATC,GAA8B,OAATA,EAC9BqB,EAAUrB,OACL,QAAoB,IAATA,EAChB,MAAM,IAAIjC,UAAU,qCAEjB,GAAIgC,aAAgBV,YAEzB,GADA4C,EAAuBlC,EACH,iBAATC,GAA8B,OAATA,EAC9BqB,EAAUrB,OACL,QAAoB,IAATA,EAChB,MAAM,IAAIjC,UAAU,oCAEjB,MACHgC,aAAgBmC,aACc,oBAAtBC,mBAAqCpC,aAAgBoC,mBAoC/D,MAAM,IAAIpE,UAAU,uDApC+D,CACnF,MAAMqE,EAASrC,EACf,IAAIsC,EAAa,EACbC,EAAavC,EAAKuC,WACtB,GAAoB,iBAATtC,GAA8B,OAATA,EAC9BqB,EAAUrB,OACL,GAAoB,iBAATA,EAAmB,CAEnC,GADAqC,EAAarC,GACRa,OAAOC,cAAcuB,GACxB,MAAM,IAAItB,WAAW,oCAEvB,GAAIsB,EAAa,GAAKA,GAAcD,EAAOE,WACzC,MAAM,IAAIvB,WAAW,oCAAoCqB,EAAOE,gBAGlE,GADAA,EAAavC,EAAKuC,WAAaD,EACX,iBAATpC,EAAmB,CAE5B,GADAqC,EAAarC,GACRY,OAAOC,cAAcwB,GACxB,MAAM,IAAIvB,WAAW,oCAEvB,GAAIuB,GAAc,GAAKD,EAAaC,EAAaF,EAAOE,WACtD,MAAM,IAAIvB,WAAW,oCAAoCqB,EAAOE,WAAaD,OAE/E,GAAoB,iBAATL,GAA8B,OAATA,EAC9BX,EAAUW,OACL,QAAoB,IAATA,EAChB,MAAM,IAAIjE,UAAU,qCAEjB,QAAoB,IAATkC,EAChB,MAAM,IAAIlC,UAAU,uCAEjB,QAAoB,IAATiC,EAChB,MAAM,IAAIjC,UAAU,gCAEtBkE,EAAuB,IAAI5C,WAAW+C,EAAQC,EAAYC,IAM5D,MACMC,GADMlB,EAAQmB,oBAAsB,IACjBC,KAAItE,GAAkB,iBAANA,EAAiBA,EAAIA,EAAET,OAC1DC,OL9HoB+E,OAAMH,IAClC,MAAMI,EAAuC,IAAxBJ,EAAanE,OAAeZ,EAA2B+E,EACtEK,EAAS,GACf,IAAK,MAAMC,KAAeF,EAAc,CACtC,MAAMG,EAAcvF,EAASsF,GAC7B,GAAIC,EAAa,CACf,GAAIA,EAAYC,YACd,OAAOD,EAAYnF,QACd,GAAImF,EAAYE,QACrB,SAGF,MAAMC,IAAmBH,EAAYI,YACrC,IAME,OALKD,IACHH,EAAYI,YAAcJ,EAAYnF,QAAQE,cAE1CiF,EAAYI,YAClBJ,EAAYC,aAAc,EACnBD,EAAYnF,QACnB,MAAOwF,GACFF,GACHL,EAAOtE,KAAK,CAACZ,KAAMmF,EAAaO,IAAKD,IAEvCL,EAAYE,SAAU,E,eAEfF,EAAYI,cAKzB,MAAM,IAAIhF,MAAM,oCAAoC0E,EAAOH,KAAIU,GAAK,IAAIA,EAAEzF,SAASyF,EAAEC,QAAOC,KAAK,UK+FzEC,CAAef,GAC/BrB,QAAgBvD,EAAQG,qBAAqBmE,EAAsBZ,GACzE,OAAO,IAAIJ,EAAiBC,GAG9B,iBACE1C,KAAK0C,QAAQqC,iBAEf,eACE/E,KAAK0C,QAAQsC,eAGf,iBACE,OAAOhF,KAAK0C,QAAQU,WAEtB,kBACE,OAAOpD,KAAK0C,QAAQK,aC6KjB,MAAM,EAA4CN,E","file":"ort-common.node.js","sourcesContent":["// The require scope\nvar __webpack_require__ = {};\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport {Backend} from './backend';\r\n\r\ninterface BackendInfo {\r\n  backend: Backend;\r\n  priority: number;\r\n\r\n  initPromise?: Promise<void>;\r\n  initialized?: boolean;\r\n  aborted?: boolean;\r\n}\r\n\r\nconst backends: {[name: string]: BackendInfo} = {};\r\nconst backendsSortedByPriority: string[] = [];\r\n\r\n/**\r\n * Register a backend.\r\n *\r\n * @param name - the name as a key to lookup as an execution provider.\r\n * @param backend - the backend object.\r\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\r\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\r\n *\r\n * @internal\r\n */\r\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\r\n  if (backend && typeof backend.init === 'function' && typeof backend.createSessionHandler === 'function') {\r\n    const currentBackend = backends[name];\r\n    if (currentBackend === undefined) {\r\n      backends[name] = {backend, priority};\r\n    } else if (currentBackend.backend === backend) {\r\n      return;\r\n    } else {\r\n      throw new Error(`backend \"${name}\" is already registered`);\r\n    }\r\n\r\n    if (priority >= 0) {\r\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\r\n        if (backends[backendsSortedByPriority[i]].priority <= priority) {\r\n          backendsSortedByPriority.splice(i, 0, name);\r\n          return;\r\n        }\r\n      }\r\n      backendsSortedByPriority.push(name);\r\n    }\r\n    return;\r\n  }\r\n\r\n  throw new TypeError('not a valid backend');\r\n};\r\n\r\n/**\r\n * Resolve backend by specified hints.\r\n *\r\n * @param backendHints - a list of execution provider names to lookup. If omitted use registered backends as list.\r\n * @returns a promise that resolves to the backend.\r\n *\r\n * @internal\r\n */\r\nexport const resolveBackend = async(backendHints: readonly string[]): Promise<Backend> => {\r\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\r\n  const errors = [];\r\n  for (const backendName of backendNames) {\r\n    const backendInfo = backends[backendName];\r\n    if (backendInfo) {\r\n      if (backendInfo.initialized) {\r\n        return backendInfo.backend;\r\n      } else if (backendInfo.aborted) {\r\n        continue;  // current backend is unavailable; try next\r\n      }\r\n\r\n      const isInitializing = !!backendInfo.initPromise;\r\n      try {\r\n        if (!isInitializing) {\r\n          backendInfo.initPromise = backendInfo.backend.init();\r\n        }\r\n        await backendInfo.initPromise;\r\n        backendInfo.initialized = true;\r\n        return backendInfo.backend;\r\n      } catch (e) {\r\n        if (!isInitializing) {\r\n          errors.push({name: backendName, err: e});\r\n        }\r\n        backendInfo.aborted = true;\r\n      } finally {\r\n        delete backendInfo.initPromise;\r\n      }\r\n    }\r\n  }\r\n\r\n  throw new Error(`no available backend found. ERR: ${errors.map(e => `[${e.name}] ${e.err}`).join(', ')}`);\r\n};\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport {EnvImpl} from './env-impl';\r\nexport declare namespace Env {\r\n  export type WasmPrefixOrFilePaths = string|{\r\n    'ort-wasm.wasm'?: string;\r\n    'ort-wasm-threaded.wasm'?: string;\r\n    'ort-wasm-simd.wasm'?: string;\r\n    'ort-wasm-simd-threaded.wasm'?: string;\r\n  };\r\n  export interface WebAssemblyFlags {\r\n    /**\r\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\r\n     * to 1, no worker thread will be spawned.\r\n     *\r\n     * This setting is available only when WebAssembly multithread feature is available in current context.\r\n     *\r\n     * @defaultValue `0`\r\n     */\r\n    numThreads?: number;\r\n\r\n    /**\r\n     * set or get a boolean value indicating whether to enable SIMD. If set to false, SIMD will be forcely disabled.\r\n     *\r\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\r\n     *\r\n     * @defaultValue `true`\r\n     */\r\n    simd?: boolean;\r\n\r\n    /**\r\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\r\n     * value indicates no timeout is set.\r\n     *\r\n     * @defaultValue `0`\r\n     */\r\n    initTimeout?: number;\r\n\r\n    /**\r\n     * Set a custom URL prefix to the .wasm files or a set of overrides for each .wasm file. The override path should be\r\n     * an absolute path.\r\n     */\r\n    wasmPaths?: WasmPrefixOrFilePaths;\r\n\r\n    /**\r\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\r\n     *\r\n     * @defaultValue `false`\r\n     */\r\n    proxy?: boolean;\r\n  }\r\n\r\n  export interface WebGLFlags {\r\n    /**\r\n     * Set or get the WebGL Context ID (webgl or webgl2).\r\n     *\r\n     * @defaultValue `'webgl2'`\r\n     */\r\n    contextId?: 'webgl'|'webgl2';\r\n    /**\r\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\r\n     *\r\n     * @deprecated\r\n     */\r\n    matmulMaxBatchSize?: number;\r\n    /**\r\n     * Set or get the texture cache mode.\r\n     *\r\n     * @defaultValue `'full'`\r\n     */\r\n    textureCacheMode?: 'initializerOnly'|'full';\r\n    /**\r\n     * Set or get the packed texture mode\r\n     *\r\n     * @defaultValue `false`\r\n     */\r\n    pack?: boolean;\r\n    /**\r\n     * Set or get whether enable async download.\r\n     *\r\n     * @defaultValue `false`\r\n     */\r\n    async?: boolean;\r\n  }\r\n}\r\n\r\nexport interface Env {\r\n  /**\r\n   * set the severity level for logging.\r\n   *\r\n   * @defaultValue `'warning'`\r\n   */\r\n  logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal';\r\n  /**\r\n   * Indicate whether run in debug mode.\r\n   *\r\n   * @defaultValue `false`\r\n   */\r\n  debug?: boolean;\r\n\r\n  /**\r\n   * Represent a set of flags for WebAssembly\r\n   */\r\n  wasm: Env.WebAssemblyFlags;\r\n\r\n  /**\r\n   * Represent a set of flags for WebGL\r\n   */\r\n  webgl: Env.WebGLFlags;\r\n\r\n  [name: string]: unknown;\r\n}\r\n\r\n/**\r\n * Represent a set of flags as a global singleton.\r\n */\r\nexport const env: Env = new EnvImpl();\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport {Env} from './env';\r\n\r\ntype LogLevelType = Env['logLevel'];\r\nexport class EnvImpl implements Env {\r\n  constructor() {\r\n    this.wasm = {};\r\n    this.webgl = {};\r\n    this.logLevelInternal = 'warning';\r\n  }\r\n\r\n  // TODO standadize the getter and setter convention in env for other fields.\r\n  set logLevel(value: LogLevelType) {\r\n    if (value === undefined) {\r\n      return;\r\n    }\r\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\r\n      throw new Error(`Unsupported logging level: ${value}`);\r\n    }\r\n    this.logLevelInternal = value;\r\n  }\r\n  get logLevel(): LogLevelType {\r\n    return this.logLevelInternal;\r\n  }\r\n\r\n  debug?: boolean;\r\n\r\n  wasm: Env.WebAssemblyFlags;\r\n\r\n  webgl: Env.WebGLFlags;\r\n\r\n  [name: string]: unknown;\r\n\r\n  private logLevelInternal: Required<LogLevelType>;\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport {Tensor as TensorInterface} from './tensor';\r\n\r\ntype TensorType = TensorInterface.Type;\r\ntype TensorDataType = TensorInterface.DataType;\r\n\r\ntype SupportedTypedArrayConstructors = Float32ArrayConstructor|Uint8ArrayConstructor|Int8ArrayConstructor|\r\n    Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|Uint8ArrayConstructor|\r\n    Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor;\r\ntype SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\r\n\r\nconst isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && typeof BigInt64Array.from === 'function';\r\nconst isBigUint64ArrayAvailable = typeof BigUint64Array !== 'undefined' && typeof BigUint64Array.from === 'function';\r\n\r\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\r\nconst NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\r\n  ['float32', Float32Array],\r\n  ['uint8', Uint8Array],\r\n  ['int8', Int8Array],\r\n  ['uint16', Uint16Array],\r\n  ['int16', Int16Array],\r\n  ['int32', Int32Array],\r\n  ['bool', Uint8Array],\r\n  ['float64', Float64Array],\r\n  ['uint32', Uint32Array],\r\n]);\r\n\r\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\r\nconst NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, TensorType>([\r\n  [Float32Array, 'float32'],\r\n  [Uint8Array, 'uint8'],\r\n  [Int8Array, 'int8'],\r\n  [Uint16Array, 'uint16'],\r\n  [Int16Array, 'int16'],\r\n  [Int32Array, 'int32'],\r\n  [Float64Array, 'float64'],\r\n  [Uint32Array, 'uint32'],\r\n]);\r\n\r\nif (isBigInt64ArrayAvailable) {\r\n  NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\r\n  NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\r\n}\r\nif (isBigUint64ArrayAvailable) {\r\n  NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\r\n  NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\r\n}\r\n\r\n/**\r\n * calculate size from dims.\r\n *\r\n * @param dims the dims array. May be an illegal input.\r\n */\r\nconst calculateSize = (dims: readonly unknown[]): number => {\r\n  let size = 1;\r\n  for (let i = 0; i < dims.length; i++) {\r\n    const dim = dims[i];\r\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\r\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\r\n    }\r\n    if (dim < 0) {\r\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\r\n    }\r\n    size *= dim;\r\n  }\r\n  return size;\r\n};\r\n\r\nexport class Tensor implements TensorInterface {\r\n  //#region constructors\r\n  constructor(type: TensorType, data: TensorDataType|readonly number[]|readonly boolean[], dims?: readonly number[]);\r\n  constructor(data: TensorDataType|readonly boolean[], dims?: readonly number[]);\r\n  constructor(\r\n      arg0: TensorType|TensorDataType|readonly boolean[], arg1?: TensorDataType|readonly number[]|readonly boolean[],\r\n      arg2?: readonly number[]) {\r\n    let type: TensorType;\r\n    let data: TensorDataType;\r\n    let dims: typeof arg1|typeof arg2;\r\n    // check whether arg0 is type or data\r\n    if (typeof arg0 === 'string') {\r\n      //\r\n      // Override: constructor(type, data, ...)\r\n      //\r\n      type = arg0;\r\n      dims = arg2;\r\n      if (arg0 === 'string') {\r\n        // string tensor\r\n        if (!Array.isArray(arg1)) {\r\n          throw new TypeError('A string tensor\\'s data must be a string array.');\r\n        }\r\n        // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\r\n        // error will be populated at inference\r\n        data = arg1;\r\n      } else {\r\n        // numeric tensor\r\n        const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\r\n        if (typedArrayConstructor === undefined) {\r\n          throw new TypeError(`Unsupported tensor type: ${arg0}.`);\r\n        }\r\n        if (Array.isArray(arg1)) {\r\n          // use 'as any' here because TypeScript's check on type of 'SupportedTypedArrayConstructors.from()' produces\r\n          // incorrect results.\r\n          // 'typedArrayConstructor' should be one of the typed array prototype objects.\r\n          // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n          data = (typedArrayConstructor as any).from(arg1);\r\n        } else if (arg1 instanceof typedArrayConstructor) {\r\n          data = arg1;\r\n        } else {\r\n          throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\r\n        }\r\n      }\r\n    } else {\r\n      //\r\n      // Override: constructor(data, ...)\r\n      //\r\n      dims = arg1;\r\n      if (Array.isArray(arg0)) {\r\n        // only boolean[] and string[] is supported\r\n        if (arg0.length === 0) {\r\n          throw new TypeError('Tensor type cannot be inferred from an empty array.');\r\n        }\r\n        const firstElementType = typeof arg0[0];\r\n        if (firstElementType === 'string') {\r\n          type = 'string';\r\n          data = arg0;\r\n        } else if (firstElementType === 'boolean') {\r\n          type = 'bool';\r\n          // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\r\n          // wrong type. We use 'as any' to make it happy.\r\n          // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n          data = Uint8Array.from(arg0 as any[]);\r\n        } else {\r\n          throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\r\n        }\r\n      } else {\r\n        // get tensor type from TypedArray\r\n        const mappedType =\r\n            NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(arg0.constructor as SupportedTypedArrayConstructors);\r\n        if (mappedType === undefined) {\r\n          throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\r\n        }\r\n        type = mappedType;\r\n        data = arg0 as SupportedTypedArray;\r\n      }\r\n    }\r\n\r\n    // type and data is processed, now processing dims\r\n    if (dims === undefined) {\r\n      // assume 1-D tensor if dims omitted\r\n      dims = [data.length];\r\n    } else if (!Array.isArray(dims)) {\r\n      throw new TypeError('A tensor\\'s dims must be a number array');\r\n    }\r\n\r\n    // perform check\r\n    const size = calculateSize(dims);\r\n    if (size !== data.length) {\r\n      throw new Error(`Tensor's size(${size}) does not match data length(${data.length}).`);\r\n    }\r\n\r\n    this.dims = dims as readonly number[];\r\n    this.type = type;\r\n    this.data = data;\r\n    this.size = size;\r\n  }\r\n  //#endregion\r\n\r\n  //#region fields\r\n  readonly dims: readonly number[];\r\n  readonly type: TensorType;\r\n  readonly data: TensorDataType;\r\n  readonly size: number;\r\n  //#endregion\r\n\r\n  //#region tensor utilities\r\n  reshape(dims: readonly number[]): Tensor {\r\n    return new Tensor(this.type, this.data, dims);\r\n  }\r\n  //#endregion\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport {Tensor as TensorImpl} from './tensor-impl';\r\nimport {TypedTensorUtils} from './tensor-utils';\r\n\r\n/* eslint-disable @typescript-eslint/no-redeclare */\r\n\r\n/**\r\n * represent a basic tensor with specified dimensions and data type.\r\n */\r\ninterface TypedTensorBase<T extends Tensor.Type> {\r\n  /**\r\n   * Get the dimensions of the tensor.\r\n   */\r\n  readonly dims: readonly number[];\r\n  /**\r\n   * Get the data type of the tensor.\r\n   */\r\n  readonly type: T;\r\n  /**\r\n   * Get the buffer data of the tensor.\r\n   */\r\n  readonly data: Tensor.DataTypeMap[T];\r\n}\r\n\r\nexport declare namespace Tensor {\r\n  interface DataTypeMap {\r\n    float32: Float32Array;\r\n    uint8: Uint8Array;\r\n    int8: Int8Array;\r\n    uint16: Uint16Array;\r\n    int16: Int16Array;\r\n    int32: Int32Array;\r\n    int64: BigInt64Array;\r\n    string: string[];\r\n    bool: Uint8Array;\r\n    float16: never;  // hold on using Uint16Array before we have a concrete solution for float 16\r\n    float64: Float64Array;\r\n    uint32: Uint32Array;\r\n    uint64: BigUint64Array;\r\n    // complex64: never;\r\n    // complex128: never;\r\n    // bfloat16: never;\r\n  }\r\n\r\n  interface ElementTypeMap {\r\n    float32: number;\r\n    uint8: number;\r\n    int8: number;\r\n    uint16: number;\r\n    int16: number;\r\n    int32: number;\r\n    int64: bigint;\r\n    string: string;\r\n    bool: boolean;\r\n    float16: never;  // hold on before we have a concret solution for float 16\r\n    float64: number;\r\n    uint32: number;\r\n    uint64: bigint;\r\n    // complex64: never;\r\n    // complex128: never;\r\n    // bfloat16: never;\r\n  }\r\n\r\n  type DataType = DataTypeMap[Type];\r\n  type ElementType = ElementTypeMap[Type];\r\n\r\n  /**\r\n   * represent the data type of a tensor\r\n   */\r\n  export type Type = keyof DataTypeMap;\r\n}\r\n\r\n/**\r\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\r\n */\r\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\r\n/**\r\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\r\n */\r\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\r\n\r\nexport interface TensorConstructor {\r\n  //#region specify element type\r\n  /**\r\n   * Construct a new string tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(type: 'string', data: Tensor.DataTypeMap['string']|readonly string[],\r\n      dims?: readonly number[]): TypedTensor<'string'>;\r\n\r\n  /**\r\n   * Construct a new bool tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(type: 'bool', data: Tensor.DataTypeMap['bool']|readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\r\n\r\n  /**\r\n   * Construct a new numeric tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new<T extends Exclude<Tensor.Type, 'string'|'bool'>>(\r\n      type: T, data: Tensor.DataTypeMap[T]|readonly number[], dims?: readonly number[]): TypedTensor<T>;\r\n  //#endregion\r\n\r\n  //#region infer element types\r\n\r\n  /**\r\n   * Construct a new float32 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\r\n\r\n  /**\r\n   * Construct a new int8 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\r\n\r\n  /**\r\n   * Construct a new uint8 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\r\n\r\n  /**\r\n   * Construct a new uint16 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\r\n\r\n  /**\r\n   * Construct a new int16 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\r\n\r\n  /**\r\n   * Construct a new int32 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\r\n\r\n  /**\r\n   * Construct a new int64 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\r\n\r\n  /**\r\n   * Construct a new string tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\r\n\r\n  /**\r\n   * Construct a new bool tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\r\n\r\n  /**\r\n   * Construct a new float64 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\r\n\r\n  /**\r\n   * Construct a new uint32 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\r\n\r\n  /**\r\n   * Construct a new uint64 tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\r\n\r\n  //#endregion\r\n\r\n  //#region fall back to non-generic tensor type declaration\r\n\r\n  /**\r\n   * Construct a new tensor object from the given type, data and dims.\r\n   *\r\n   * @param type - Specify the element type.\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(type: Tensor.Type, data: Tensor.DataType|readonly number[]|readonly boolean[], dims?: readonly number[]): Tensor;\r\n\r\n  /**\r\n   * Construct a new tensor object from the given data and dims.\r\n   *\r\n   * @param data - Specify the tensor data\r\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\r\n   */\r\n  new(data: Tensor.DataType, dims?: readonly number[]): Tensor;\r\n  //#endregion\r\n}\r\n\r\n// eslint-disable-next-line @typescript-eslint/naming-convention\r\nexport const Tensor = TensorImpl as TensorConstructor;\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport {SessionHandler} from './backend';\r\nimport {resolveBackend} from './backend-impl';\r\nimport {InferenceSession as InferenceSessionInterface} from './inference-session';\r\nimport {OnnxValue} from './onnx-value';\r\nimport {Tensor} from './tensor';\r\n\r\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\r\ntype RunOptions = InferenceSessionInterface.RunOptions;\r\ntype FeedsType = InferenceSessionInterface.FeedsType;\r\ntype FetchesType = InferenceSessionInterface.FetchesType;\r\ntype ReturnType = InferenceSessionInterface.ReturnType;\r\n\r\nexport class InferenceSession implements InferenceSessionInterface {\r\n  private constructor(handler: SessionHandler) {\r\n    this.handler = handler;\r\n  }\r\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\r\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\r\n  async run(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\r\n    const fetches: {[name: string]: OnnxValue|null} = {};\r\n    let options: RunOptions = {};\r\n    // check inputs\r\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\r\n      throw new TypeError(\r\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\r\n    }\r\n\r\n    let isFetchesEmpty = true;\r\n    // determine which override is being used\r\n    if (typeof arg1 === 'object') {\r\n      if (arg1 === null) {\r\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\r\n      }\r\n      if (arg1 instanceof Tensor) {\r\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\r\n      }\r\n\r\n      if (Array.isArray(arg1)) {\r\n        if (arg1.length === 0) {\r\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\r\n        }\r\n        isFetchesEmpty = false;\r\n        // output names\r\n        for (const name of arg1) {\r\n          if (typeof name !== 'string') {\r\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\r\n          }\r\n          if (this.outputNames.indexOf(name) === -1) {\r\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\r\n          }\r\n          fetches[name] = null;\r\n        }\r\n\r\n        if (typeof arg2 === 'object' && arg2 !== null) {\r\n          options = arg2;\r\n        } else if (typeof arg2 !== 'undefined') {\r\n          throw new TypeError('\\'options\\' must be an object.');\r\n        }\r\n      } else {\r\n        // decide whether arg1 is fetches or options\r\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\r\n        let isFetches = false;\r\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\r\n        for (const name of this.outputNames) {\r\n          if (arg1Keys.indexOf(name) !== -1) {\r\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\r\n            if (v === null || v instanceof Tensor) {\r\n              isFetches = true;\r\n              isFetchesEmpty = false;\r\n              fetches[name] = v;\r\n            }\r\n          }\r\n        }\r\n\r\n        if (isFetches) {\r\n          if (typeof arg2 === 'object' && arg2 !== null) {\r\n            options = arg2;\r\n          } else if (typeof arg2 !== 'undefined') {\r\n            throw new TypeError('\\'options\\' must be an object.');\r\n          }\r\n        } else {\r\n          options = arg1 as RunOptions;\r\n        }\r\n      }\r\n    } else if (typeof arg1 !== 'undefined') {\r\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\r\n    }\r\n\r\n    // check if all inputs are in feed\r\n    for (const name of this.inputNames) {\r\n      if (typeof feeds[name] === 'undefined') {\r\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\r\n      }\r\n    }\r\n\r\n    // if no fetches is specified, we use the full output names list\r\n    if (isFetchesEmpty) {\r\n      for (const name of this.outputNames) {\r\n        fetches[name] = null;\r\n      }\r\n    }\r\n\r\n    // feeds, fetches and options are prepared\r\n\r\n    const results = await this.handler.run(feeds, fetches, options);\r\n    const returnValue: {[name: string]: OnnxValue} = {};\r\n    for (const key in results) {\r\n      if (Object.hasOwnProperty.call(results, key)) {\r\n        returnValue[key] = new Tensor(results[key].type, results[key].data, results[key].dims);\r\n      }\r\n    }\r\n    return returnValue;\r\n  }\r\n\r\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\r\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\r\n  static create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: SessionOptions):\r\n      Promise<InferenceSessionInterface>;\r\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\r\n  static async create(\r\n      arg0: string|ArrayBufferLike|Uint8Array, arg1?: SessionOptions|number, arg2?: number,\r\n      arg3?: SessionOptions): Promise<InferenceSessionInterface> {\r\n    // either load from a file or buffer\r\n    let filePathOrUint8Array: string|Uint8Array;\r\n    let options: SessionOptions = {};\r\n\r\n    if (typeof arg0 === 'string') {\r\n      filePathOrUint8Array = arg0;\r\n      if (typeof arg1 === 'object' && arg1 !== null) {\r\n        options = arg1;\r\n      } else if (typeof arg1 !== 'undefined') {\r\n        throw new TypeError('\\'options\\' must be an object.');\r\n      }\r\n    } else if (arg0 instanceof Uint8Array) {\r\n      filePathOrUint8Array = arg0;\r\n      if (typeof arg1 === 'object' && arg1 !== null) {\r\n        options = arg1;\r\n      } else if (typeof arg1 !== 'undefined') {\r\n        throw new TypeError('\\'options\\' must be an object.');\r\n      }\r\n    } else if (\r\n        arg0 instanceof ArrayBuffer ||\r\n        (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)) {\r\n      const buffer = arg0;\r\n      let byteOffset = 0;\r\n      let byteLength = arg0.byteLength;\r\n      if (typeof arg1 === 'object' && arg1 !== null) {\r\n        options = arg1;\r\n      } else if (typeof arg1 === 'number') {\r\n        byteOffset = arg1;\r\n        if (!Number.isSafeInteger(byteOffset)) {\r\n          throw new RangeError('\\'byteOffset\\' must be an integer.');\r\n        }\r\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\r\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\r\n        }\r\n        byteLength = arg0.byteLength - byteOffset;\r\n        if (typeof arg2 === 'number') {\r\n          byteLength = arg2;\r\n          if (!Number.isSafeInteger(byteLength)) {\r\n            throw new RangeError('\\'byteLength\\' must be an integer.');\r\n          }\r\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\r\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\r\n          }\r\n          if (typeof arg3 === 'object' && arg3 !== null) {\r\n            options = arg3;\r\n          } else if (typeof arg3 !== 'undefined') {\r\n            throw new TypeError('\\'options\\' must be an object.');\r\n          }\r\n        } else if (typeof arg2 !== 'undefined') {\r\n          throw new TypeError('\\'byteLength\\' must be a number.');\r\n        }\r\n      } else if (typeof arg1 !== 'undefined') {\r\n        throw new TypeError('\\'options\\' must be an object.');\r\n      }\r\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\r\n    } else {\r\n      throw new TypeError('Unexpected argument[0]: must be \\'path\\' or \\'buffer\\'.');\r\n    }\r\n\r\n    // get backend hints\r\n    const eps = options.executionProviders || [];\r\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\r\n    const backend = await resolveBackend(backendHints);\r\n    const handler = await backend.createSessionHandler(filePathOrUint8Array, options);\r\n    return new InferenceSession(handler);\r\n  }\r\n\r\n  startProfiling(): void {\r\n    this.handler.startProfiling();\r\n  }\r\n  endProfiling(): void {\r\n    this.handler.endProfiling();\r\n  }\r\n\r\n  get inputNames(): readonly string[] {\r\n    return this.handler.inputNames;\r\n  }\r\n  get outputNames(): readonly string[] {\r\n    return this.handler.outputNames;\r\n  }\r\n\r\n  private handler: SessionHandler;\r\n}\r\n","// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT License.\r\n\r\nimport {InferenceSession as InferenceSessionImpl} from './inference-session-impl';\r\nimport {OnnxValue} from './onnx-value';\r\n\r\n/* eslint-disable @typescript-eslint/no-redeclare */\r\n\r\nexport declare namespace InferenceSession {\r\n  //#region input/output types\r\n\r\n  type OnnxValueMapType = {readonly [name: string]: OnnxValue};\r\n  type NullableOnnxValueMapType = {readonly [name: string]: OnnxValue | null};\r\n\r\n  /**\r\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\r\n   */\r\n  type FeedsType = OnnxValueMapType;\r\n\r\n  /**\r\n   * A fetches (model outputs) could be one of the following:\r\n   *\r\n   * - Omitted. Use model's output names definition.\r\n   * - An array of string indicating the output names.\r\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\r\n   *\r\n   * @remark\r\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\r\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\r\n   * internally.\r\n   */\r\n  type FetchesType = readonly string[]|NullableOnnxValueMapType;\r\n\r\n  /**\r\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\r\n   */\r\n  type ReturnType = OnnxValueMapType;\r\n\r\n  //#endregion\r\n\r\n  //#region session options\r\n\r\n  /**\r\n   * A set of configurations for session behavior.\r\n   */\r\n  export interface SessionOptions {\r\n    /**\r\n     * An array of execution provider options.\r\n     *\r\n     * An execution provider option can be a string indicating the name of the execution provider,\r\n     * or an object of corresponding type.\r\n     */\r\n    executionProviders?: readonly ExecutionProviderConfig[];\r\n\r\n    /**\r\n     * The intra OP threads number.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\r\n     */\r\n    intraOpNumThreads?: number;\r\n\r\n    /**\r\n     * The inter OP threads number.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\r\n     */\r\n    interOpNumThreads?: number;\r\n\r\n    /**\r\n     * The optimization level.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    graphOptimizationLevel?: 'disabled'|'basic'|'extended'|'all';\r\n\r\n    /**\r\n     * Whether enable CPU memory arena.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    enableCpuMemArena?: boolean;\r\n\r\n    /**\r\n     * Whether enable memory pattern.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    enableMemPattern?: boolean;\r\n\r\n    /**\r\n     * Execution mode.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    executionMode?: 'sequential'|'parallel';\r\n\r\n    /**\r\n     * Wether enable profiling.\r\n     *\r\n     * This setting is a placeholder for a future use.\r\n     */\r\n    enableProfiling?: boolean;\r\n\r\n    /**\r\n     * File prefix for profiling.\r\n     *\r\n     * This setting is a placeholder for a future use.\r\n     */\r\n    profileFilePrefix?: string;\r\n\r\n    /**\r\n     * Log ID.\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    logId?: string;\r\n\r\n    /**\r\n     * Log severity level. See\r\n     * https://github.com/microsoft/onnxruntime/blob/master/include/onnxruntime/core/common/logging/severity.h\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    logSeverityLevel?: 0|1|2|3|4;\r\n\r\n    /**\r\n     * Log verbosity level.\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     */\r\n    logVerbosityLevel?: number;\r\n\r\n    /**\r\n     * Store configurations for a session. See\r\n     * https://github.com/microsoft/onnxruntime/blob/master/include/onnxruntime/core/session/\r\n     * onnxruntime_session_options_config_keys.h\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     *\r\n     * @example\r\n     * ```js\r\n     * extra: {\r\n     *   session: {\r\n     *     set_denormal_as_zero: \"1\",\r\n     *     disable_prepacking: \"1\"\r\n     *   },\r\n     *   optimization: {\r\n     *     enable_gelu_approximation: \"1\"\r\n     *   }\r\n     * }\r\n     * ```\r\n     */\r\n    extra?: Record<string, unknown>;\r\n  }\r\n\r\n  //#region execution providers\r\n\r\n  // Currently, we have the following backends to support execution providers:\r\n  // Backend Node.js binding: supports 'cpu' and 'cuda'.\r\n  // Backend WebAssembly: supports 'wasm'.\r\n  // Backend ONNX.js: supports 'webgl'.\r\n  interface ExecutionProviderOptionMap {\r\n    cpu: CpuExecutionProviderOption;\r\n    cuda: CudaExecutionProviderOption;\r\n    wasm: WebAssemblyExecutionProviderOption;\r\n    webgl: WebGLExecutionProviderOption;\r\n  }\r\n\r\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\r\n  type ExecutionProviderConfig =\r\n      ExecutionProviderOptionMap[ExecutionProviderName]|ExecutionProviderOption|ExecutionProviderName|string;\r\n\r\n  export interface ExecutionProviderOption {\r\n    readonly name: string;\r\n  }\r\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'cpu';\r\n    useArena?: boolean;\r\n  }\r\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'cuda';\r\n    deviceId?: number;\r\n  }\r\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'wasm';\r\n    // TODO: add flags\r\n  }\r\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\r\n    readonly name: 'webgl';\r\n    // TODO: add flags\r\n  }\r\n  //#endregion\r\n\r\n  //#endregion\r\n\r\n  //#region run options\r\n\r\n  /**\r\n   * A set of configurations for inference run behavior\r\n   */\r\n  export interface RunOptions {\r\n    /**\r\n     * Log severity level. See\r\n     * https://github.com/microsoft/onnxruntime/blob/master/include/onnxruntime/core/common/logging/severity.h\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    logSeverityLevel?: 0|1|2|3|4;\r\n\r\n    /**\r\n     * Log verbosity level.\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     */\r\n    logVerbosityLevel?: number;\r\n\r\n    /**\r\n     * Terminate all incomplete OrtRun calls as soon as possible if true\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     */\r\n    terminate?: boolean;\r\n\r\n    /**\r\n     * A tag for the Run() calls using this\r\n     *\r\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\r\n     */\r\n    tag?: string;\r\n\r\n    /**\r\n     * Set a single run configuration entry. See\r\n     * https://github.com/microsoft/onnxruntime/blob/master/include/onnxruntime/core/session/\r\n     * onnxruntime_run_options_config_keys.h\r\n     *\r\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\r\n     *\r\n     * @example\r\n     *\r\n     * ```js\r\n     * extra: {\r\n     *   memory: {\r\n     *     enable_memory_arena_shrinkage: \"1\",\r\n     *   }\r\n     * }\r\n     * ```\r\n     */\r\n    extra?: Record<string, unknown>;\r\n  }\r\n\r\n  //#endregion\r\n\r\n  //#region value metadata\r\n\r\n  // eslint-disable-next-line @typescript-eslint/no-empty-interface\r\n  interface ValueMetadata {\r\n    // TBD\r\n  }\r\n\r\n  //#endregion\r\n}\r\n\r\n/**\r\n * Represent a runtime instance of an ONNX model.\r\n */\r\nexport interface InferenceSession {\r\n  //#region run()\r\n\r\n  /**\r\n   * Execute the model asynchronously with the given feeds and options.\r\n   *\r\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\r\n   * @param options - Optional. A set of options that controls the behavior of model inference.\r\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\r\n   */\r\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\r\n\r\n  /**\r\n   * Execute the model asynchronously with the given feeds, fetches and options.\r\n   *\r\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\r\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\r\n   * detail.\r\n   * @param options - Optional. A set of options that controls the behavior of model inference.\r\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\r\n   */\r\n  run(feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\r\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\r\n\r\n  //#endregion\r\n\r\n  //#region profiling\r\n\r\n  /**\r\n   * Start profiling.\r\n   */\r\n  startProfiling(): void;\r\n\r\n  /**\r\n   * End profiling.\r\n   */\r\n  endProfiling(): void;\r\n\r\n  //#endregion\r\n\r\n  //#region metadata\r\n\r\n  /**\r\n   * Get input names of the loaded model.\r\n   */\r\n  readonly inputNames: readonly string[];\r\n\r\n  /**\r\n   * Get output names of the loaded model.\r\n   */\r\n  readonly outputNames: readonly string[];\r\n\r\n  // /**\r\n  //  * Get input metadata of the loaded model.\r\n  //  */\r\n  // readonly inputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\r\n\r\n  // /**\r\n  //  * Get output metadata of the loaded model.\r\n  //  */\r\n  // readonly outputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\r\n\r\n  //#endregion\r\n}\r\n\r\nexport interface InferenceSessionFactory {\r\n  //#region create()\r\n\r\n  /**\r\n   * Create a new inference session and load model asynchronously from an ONNX model file.\r\n   *\r\n   * @param uri - The URI or file path of the model to load.\r\n   * @param options - specify configuration for creating a new inference session.\r\n   * @returns A promise that resolves to an InferenceSession object.\r\n   */\r\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\r\n\r\n  /**\r\n   * Create a new inference session and load model asynchronously from an array bufer.\r\n   *\r\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\r\n   * @param options - specify configuration for creating a new inference session.\r\n   * @returns A promise that resolves to an InferenceSession object.\r\n   */\r\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\r\n\r\n  /**\r\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\r\n   *\r\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\r\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\r\n   * @param byteLength - The length in bytes of the array buffer.\r\n   * @param options - specify configuration for creating a new inference session.\r\n   * @returns A promise that resolves to an InferenceSession object.\r\n   */\r\n  create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: InferenceSession.SessionOptions):\r\n      Promise<InferenceSession>;\r\n\r\n  /**\r\n   * Create a new inference session and load model asynchronously from a Uint8Array.\r\n   *\r\n   * @param buffer - A Uint8Array representation of an ONNX model.\r\n   * @param options - specify configuration for creating a new inference session.\r\n   * @returns A promise that resolves to an InferenceSession object.\r\n   */\r\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\r\n\r\n  //#endregion\r\n}\r\n\r\n// eslint-disable-next-line @typescript-eslint/naming-convention\r\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\r\n"],"sourceRoot":""}